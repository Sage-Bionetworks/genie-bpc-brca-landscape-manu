---
title: "Survival from metastasis in a secondary-use breast cancer cohort"
output: beamer_presentation
date: "2023-08-03"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, include = F,
                      fig.width = 7, fig.height = 5,
                      warning = F, message = F)
```


```{r}
library(fs)
library(purrr)
library(here)
purrr::walk(.x = fs::dir_ls(here("R")), .f = source)
```

```{r}
# Load all the fitted models from each bootstrap resample.
boot_models_dmet_all <- readr::read_rds(
  here("data", "survival", "fit_outputs", "fit_dmet_all.rds")
)
boot_models_dmet_trip_neg <- readr::read_rds(
  here("data", "survival", "fit_outputs", "fit_dmet_trip_neg.rds")
)
boot_models_dmet_hr_pos_her2_neg <- readr::read_rds(
  here("data", "survival", "fit_outputs", "fit_dmet_hr_pos_her2_neg.rds")
)
boot_models_dmet_her2_pos <- readr::read_rds(
  here("data", "survival", "fit_outputs", "fit_dmet_her2_pos.rds")
)



# Can replace these once you go back and fix the survival function creator:
dft_dmet_surv_all <- readr::read_rds(
  file = here('data', 'survival', 'prepared_data', 'surv_dmet_all.rds')
)
dft_dmet_surv_trip_neg <- readr::read_rds(
  file = here('data', 'survival', 'prepared_data', 'surv_dmet_trip_neg.rds')
)
dft_dmet_surv_hr_pos_her2_neg <- readr::read_rds(
  file = here('data', 'survival', 'prepared_data', 'surv_dmet_hr_pos_her2_neg.rds')
)
dft_dmet_surv_her2_pos <- readr::read_rds(
  file = here('data', 'survival', 'prepared_data', 'surv_dmet_her2_pos.rds')
)

```


```{r}
# Stability filter 
coef_helper <- function(dat, filter_hr_above = 100, rel_thresh = NULL) {
  dat %<>%
    mutate(
      coef_mat = purrr::map(.x = fit, .f = get_cv_lasso_coefs)
    ) %>%
    select(-fit) %>%
    unnest(coef_mat)
  
  dat %<>%
    mutate(
      feature = forcats::fct_inorder(feature),
      hr = exp(log_hr)
    ) %>%
    filter(hr < filter_hr_above & hr > 1/filter_hr_above) %>%
    group_by(feature) %>%
    summarize(
      reliability = mean(abs(hr-1) > 0.01),
      hr = mean(hr),
      n = n()
    ) 
  
  if (!is.null(rel_thresh)) {
    dat %<>% 
      filter(reliability >= rel_thresh)
  }
  
  return(dat)
}
```




```{r}
dft_coef_dmet_os_all <- coef_helper(
  dat = boot_models_dmet_all
)
dft_coef_dmet_os_trip_neg <- coef_helper(
  dat = boot_models_dmet_trip_neg
)
dft_coef_dmet_os_hr_pos_her2_neg <- coef_helper(
  boot_models_dmet_hr_pos_her2_neg
)
dft_coef_dmet_os_her2_pos <- coef_helper(
  dat = boot_models_dmet_her2_pos
)

gg_rel_scatter_os_all <- plot_hr_rel_scatter(
  dft_coef_dmet_os_all,
  plot_title = "OS prognostic variables from distant metastasis",
  plot_subtitle = "Reliability is the frequency of identification in a boostrapped regularized LTRC Cox model"
)

gg_rel_scatter_os_trip_neg <- plot_hr_rel_scatter(
  dft_coef_dmet_os_trip_neg,
  plot_title = "OS prognostic variables from distant metastasis (triple negative subgroup)",
  plot_subtitle = "Reliability is the frequency of identification in a boostrapped regularized LTRC Cox model"
)

gg_rel_scatter_os_hr_pos_her2_neg <- plot_hr_rel_scatter(
  dft_coef_dmet_os_hr_pos_her2_neg,
  plot_title = "OS prognostic variables from distant metastasis (HR+/HER2- subgroup)",
  plot_subtitle = "Reliability is the frequency of identification in a boostrapped regularized LTRC Cox model"
)
  
gg_rel_scatter_os_her2_pos <- plot_hr_rel_scatter(
  dft_coef_dmet_os_her2_pos,
    plot_title = "OS prognostic variables from distant metastasis (HER2+ subgroup)",
  plot_subtitle = "Reliability is the frequency of identification in a boostrapped regularized LTRC Cox model"
)
```





## Setup

Characteristics of the data:

- This cohort deals with non-Sarcoma breast cancer cases (n=1100).
- While the cohort contains data from all stages, we will index from the date of metastasis here (n=818).
- Secondary-use, real-world data, curated from medical records using a common data model (PRISSMM).
- Multi-site, technically international but overwhelmingly from the east coast US.
- Participants enter the cohort (are curated) only if they have a second-generation sequencing test result, plus some additional criteria.

## Analysis

- Goal:  Assessing whether there are features which are prognostic for overall survival from metastasis.  There is a special interest in genetic features.
- Features:
  - Genetic:  Binary indicators for mutations, copy number alterations and fusions for about 150 genes which are common to all sequencing panels in the cohort.  We also required a prevalence of $>0.5\%$ for any feature.
  - Clinical:  Demographics, stage at diagnosis, etc.
- In addition to assessing this model in the entire cohort, there's interest in stratified analyses (groups as small as 150), or looking at predictive features for drug response (even smaller groups).

## Model covariates

```{r, include = T, fig.height= 3}
plot_coef_grid_flat(dft_coef_dmet_os_all, ncol = 6)
```


## Challenges

- **[left truncation]** Many participants will be diagnosed with a metastasis before a sequencing test is done.  Because we would not observe them if they died before this test, we have left truncation.
  - Note: Dependent truncation is a problem with this data, but much less when we limit and index from metastatic recurrence (part of the motivation).
- **[p>n, or close]** Particularly for subgroup analyses, we will have more features of interest than participants. 
- **[highly correlated features]** - Genes!
- **[censoring]** Nothing too unusual, but many participants are not followed to death. 

## Basic approach

- We proposed a penalized Cox model, which seems to fit all the challenges well:
  - Event time - the time from metastasis to death.
  - Truncation time - from metastasis to sequencing test (or 0 if sequencing precedes metastasis).
    - Use risk set adjustment to factor this in (assuming independent truncation).
  - LASSO or elastic net penalty, owing to our feature selection goal.  5-fold cross validation to tune the penalization parameter.
  - Features include all genetic indicator features and clinical variables potentially related to the event time.
- Additional challenge imposed by our approach:  **Instability of LASSO results**. Different seeds give wildly different sets of features.

## Addressing instability

- Xu's paper "Sparse Algorithms are not Stable.." (2008) convinced me that it's unlikely there's a magic bullet method out there that has all the nice things about LASSO with none of the instability.
- Instead, I hoped to provide readers with metrics on how stable the results were, so they could make their own decision about whether the results were trustworthy.
  - To do this, I bootstrapped the dataset, and ran the procedure 300 times.  Then I defined "reliability" as the proportion of resamples where the feature was identified (in retrospect I don't know why I didn't call this stability).
  - Coefficients were averaged on the log scale (removing one or two implausibly huge results, (like a log(HR) ~ 10).
  


---

```{r, include = T}
gg_rel_scatter_os_all
```


```{r}
binary_helper <- function(vec, zero = "Wild Type", one = "Altered") {
  case_when(
    vec %in% 0 ~ zero,
    vec %in% 1 ~ one,
    T ~ "error"
  ) %>%
    factor(., levels = c(zero, one))
}

gg_surv_dmet_all_tp53_mut <- dft_dmet_surv_all %>%
  mutate(TP53_mut = binary_helper(TP53_mut)) %>%
  plot_km_dmet_binary_strata(
    dat = .,
    strata = "TP53_mut"
  )

gg_surv_dmet_all_ERBB2_cna <- dft_dmet_surv_all %>%
  mutate(ERBB2_cna = binary_helper(ERBB2_cna)) %>%
  plot_km_dmet_binary_strata(
    dat = .,
    strata = "ERBB2_cna"
  )

gg_surv_dmet_all_stage_iv <- dft_dmet_surv_all %>%
  mutate(stage_dx_iv_num = binary_helper(
    stage_dx_iv_num,
    zero = "Stage I-III at dx",
    one = "Stage IV at dx")
  ) %>%
  plot_km_dmet_binary_strata(
    dat = .,
    strata = "stage_dx_iv_num"
  )
```


## KM plots for sanity checking

For highly relaible features, I was thinking we could show some simple KM plots to help readers with intuition, and thinking about how many participants were at risk to make these conclusions.  

The following pages show those for the top 3 most reliable features:

---

```{r, include = T}
gg_surv_dmet_all_tp53_mut
```

---

```{r, include = T}
gg_surv_dmet_all_ERBB2_cna
```

---

```{r, include = T}
gg_surv_dmet_all_stage_iv
```


## Response from collaborators

- This first result went over fairly well.  We identified two gene features (and one clinical adjustment) with known impact as highly reliable prognostic variables for OS.
- What I don't like about this:  The line for what counts as reliable is fuzzy, and most people are used to the testing paradigm and interested in drawing a line.
- Plots for the subsets were received poorly - let's look at one example (n = 147).





---

```{r, include = T}
gg_rel_scatter_os_trip_neg
```


## Complaints

- No features picked up as relaible and predictive, even those we "know" are there.
  - I'm aware this is a bad argument - a method's performance is not gauged by how much it confirms our existing beliefs.  But the fuzzy results make me wary of defending this in clinical journals.
- Unlike with the overall cohort, features with "high reliability" are actually based on a tiny number of participants, see the following KM plots.


```{r}
gg_surv_dmet_trip_neg_ATM_mut <- dft_dmet_surv_trip_neg %>%
  mutate(ATM_mut = binary_helper(ATM_mut)) %>%
  plot_km_dmet_binary_strata(
    dat = .,
    strata = "ATM_mut"
  )

gg_surv_dmet_trip_neg_PTEN_mut <- dft_dmet_surv_trip_neg %>%
  mutate(PTEN_mut = binary_helper(PTEN_mut)) %>%
  plot_km_dmet_binary_strata(
    dat = .,
    strata = "PTEN_mut"
  )
```

---

```{r, include = T}
gg_surv_dmet_trip_neg_ATM_mut
```

---

```{r, include = T}
gg_surv_dmet_trip_neg_PTEN_mut
```

## Discussion

- I want to do a targetted simluation to test whether methods are performing well.

- Data generation (discuss)

- Methods:
  - The one shown today (fixed so that copies of the same person don't end up in different folds).
  - Univariate cox models.
  - Random subsampling rather than bootstrapping.
  - Randomized lasso.
  - Stability selection.

- Metrics for success: AUC (variable selection), MSE (bias in coefficients).

## Discussion 

- All of these are in the penalized regression family.  Are there other areas I'm blind to?
- I'm currently not interested in black box methods and variable importance measures, but I have considered whether those meet our goals.






